{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b748ca-eb0d-4980-9c8d-451f5347bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q.1. Overfitting is defined as an issue which persists in ML model when model is properly trained on training data but does not work well on new \n",
    "test data as a result accuracy is good on training data, but is not good on test data. High accuracy of training data leads to low bias and low accuracy\n",
    "of test data leads to high variance.\n",
    "\n",
    "Underfitting is defined as an issue which persists in ML model when model is not properly trained on training data as well as does not work well on new \n",
    "test data as a result accuracy is not good on training data, as well as test data. Low accuracy of training data leads to high bias and low accuracy\n",
    "of test data leads to high variance.\n",
    "\n",
    "Overfitting and Underfiting can be mitigated by an generalized model which is trained well on diversified training data and has high accuracy as a result\n",
    "in new test data accuracy is also good.\n",
    "Some other methods to mitigate Overfitting and underfitting are:\n",
    "1. Hyperparameter tuning\n",
    "2. Training model on large set of data\n",
    "3. Training on diversified range of data.\n",
    "4. K fold cross validation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5a3f23-53ca-4e22-a87c-d3f4c3ae66e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q.2. Overfitting can be reduced by following methods:-\n",
    "1. Hyperparameter tuning - Before training of model some parameters are changed so as to increase the accuracy.\n",
    "2. Training the model on large set of data, so that model gives good accuracy for training data.\n",
    "3. Cross Validation technique - Suppose there are 10 sets of data. 9 sets of data are taken as training data and 1 set of data \n",
    "as test data and they are iterated 10 times taking note each set of data comes once in training, so that test data gives high accuracy.\n",
    "4. Feature Selection techiques like ANOVA and chi-square which are statistical based techniques.\n",
    "5. Monitor the model's performance during validation set and stop training if model starts degrading\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35f02c2-3424-4c0e-84c7-d2d8dc2e01e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q.3. Underfitting is defined as an issue which persists in ML model when model is not properly trained on training data as well as does not work well on new \n",
    "test data as a result accuracy is not good on training data, as well as test data. Low accuracy of training data leads to high bias and low accuracy\n",
    "of test data leads to high variance.\n",
    "Scenarios where underfitting can occur are:-\n",
    "1. Model is not properly trained on training data which gives low accuracy and testing started which further leads to low accuracy.\n",
    "2. Noise in the data - If the data contains lots of irrelevant features, then it becomes difficult for models to study underlying pattern which \n",
    "results in underfitting.\n",
    "3. Simple Model - If the model is too simple for complex task,it may result in underfitting.\n",
    "4. Insufficient features - If the important features are not included, it does not have enough information to capture underlying patterns in the data.\n",
    "5. Excessive regularisation - It leads to underfitting when regularization parameter is too high in ridge regression.\n",
    "6. Small Dataset - With a small dataset, there may not be enough examples to learn the underlying patterns effectively. As a result, even a relatively \n",
    "simple model may struggle to capture the complexity of the data, leading to underfitting.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a10f02a-feec-4c49-9c1b-e78732d24747",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q.4. Bias refers to the measure of how much prediction of the model differs from true value of the model. It makes strong assumptions about the \n",
    "underlying pattern/distribution in the data, but fails to capture the true relationship between class and target variable. It captures model's tendency \n",
    "to consistantly overpredict or underpredict target variable across different datastes. Error introduced by approximating a real world problem\n",
    "to simplified model.\n",
    "\n",
    "Variance refers to variability of model prediction across different training datasets. It is a measure of predicion of model for different training \n",
    "datasets. It is a measure of sensitivity in the dataset wrt fluctuations in the dataset. A high variance model is the one which is highly sensitive to\n",
    "training data and captures noise rather than underlying patterns.\n",
    "\n",
    "Relationship between bias and variance can be summarized as follows:-\n",
    "1. Low Bias and High variance - It leads to overfitting. Model can capture complex patterns in the data. These models have low bias and may lead to overprediction and\n",
    "underprediction of class labels. High variance is due to complexity of these models. more sensitivity to fluctuations in datsets\n",
    "2. High Bias and High Variance - It leads to underfitting. Model is too much simple and make high assumptions about the data\n",
    "to capture underlying patterns in the dataset. These are highly sensitive to fluctuations in the dataset\n",
    "simple\n",
    "3. High Bias and Low Variance - Model is too much simple and make high assumptions about the data\n",
    "to capture underlying patterns in the dataset. Models are simple and hence high variance.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "760e41da-9455-4de4-ba01-6807508fdb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q.5.\\nScenarios where overfitting can occur are:-\\n1. Model is properly trained on training data which gives high accuracy but when testing started on new data it leads to low accuracy.\\n2. Noise in the data - If the data contains lots of irrelevant features, then it becomes difficult for models to study underlying pattern which \\nresults in overfitting.\\n3. Complex Model - If the model is too complex for low size of dataset,it may result in overfitting.\\n4. Imbalanced dataset - In classification tasks, with imbalanced dataset, the model may overfit to the majority class and perform poorly on the minority class.\\n5. Inadequate regularisation - If model .\\n6. Small Dataset - With a small dataset, there may not be enough examples to learn the underlying patterns effectively. As a result, even a relatively \\nsimple model may struggle to capture the complexity of the data, leading to overfitting.\\nScenarios where underfitting can occur are:-\\n1. Model is not properly trained on training data which gives low accuracy and testing started which further leads to low accuracy.\\n2. Noise in the data - If the data contains lots of irrelevant features, then it becomes difficult for models to study underlying pattern which \\nresults in underfitting.\\n3. Simple Model - If the model is too simple for complex task,it may result in underfitting.\\n4. Insufficient features - If the important features are not included, it does not have enough information to capture underlying patterns in the data.\\n5. Excessive regularisation - It leads to underfitting when regularization parameter is too high in ridge regression.\\n6. Small Dataset - With a small dataset, there may not be enough examples to learn the underlying patterns effectively. As a result, even a relatively \\nsimple model may struggle to capture the complexity of the data, leading to underfitting.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Q.5.\n",
    "Scenarios where overfitting can occur are:-\n",
    "1. Model is properly trained on training data which gives high accuracy but when testing started on new data it leads to low accuracy.\n",
    "2. Noise in the data - If the data contains lots of irrelevant features, then it becomes difficult for models to study underlying pattern which \n",
    "results in overfitting.\n",
    "3. Complex Model - If the model is too complex for low size of dataset,it may result in overfitting.\n",
    "4. Imbalanced dataset - In classification tasks, with imbalanced dataset, the model may overfit to the majority class and perform poorly on the minority class.\n",
    "5. Inadequate regularisation - If model is not properly regularized it has too much flexibility for majoriy data which leads to overfitting.\n",
    "6. Small Dataset - With a small dataset, there may not be enough examples to learn the underlying patterns effectively. As a result, even a relatively \n",
    "simple model may struggle to capture the complexity of the data, leading to overfitting.\n",
    "Scenarios where underfitting can occur are:-\n",
    "1. Model is not properly trained on training data which gives low accuracy and testing started which further leads to low accuracy.\n",
    "2. Noise in the data - If the data contains lots of irrelevant features, then it becomes difficult for models to study underlying pattern which \n",
    "results in underfitting.\n",
    "3. Simple Model - If the model is too simple for complex task,it may result in underfitting.\n",
    "4. Insufficient features - If the important features are not included, it does not have enough information to capture underlying patterns in the data.\n",
    "5. Excessive regularisation - It leads to underfitting when regularization parameter is too high in ridge regression.\n",
    "6. Small Dataset - With a small dataset, there may not be enough examples to learn the underlying patterns effectively. As a result, even a relatively \n",
    "simple model may struggle to capture the complexity of the data, leading to underfitting.\n",
    "When accuracy of model for training data is high, and accuracy of model for test data is low it leads to low bias and high variance which results in overfitting. \n",
    "When accuracy of model for training data is low, and accuracy of model for test data is low it leads to high bias and high variance which results in overfitting. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e730bfd7-8a0b-4471-a2bd-fb12968b3acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q.6. Bias is a measure of how much prediction of model is different from true value of model, whereas variance is a measure of prediction \n",
    "of model for different training datasets .\n",
    "Variance is a measure of sensitivity in the dataset wrt fluctuations in the dataset. Bias provides model's tendency to constantly \n",
    "overpredict/underpredict target variables across different datasets.\n",
    "High Accuracy in training data leads to low bias and low accuracy in test data leads to high variance which is overfitting.\n",
    "Low accuracy in training data leads to high bias and low accuracy in test data leads to high variance which is underfitting.\n",
    "Overfitting is an example of high variance model:\n",
    "Characteristics:\n",
    "1. Complex model unable to capture underlying pattern in the data.\n",
    "2. Sensitive to fluctuation in the dataset. \n",
    "3. Captures noise in the data\n",
    "Performance:\n",
    "1. High accuracy on training data  and low accuracy on test data.\n",
    "2. Capture noise in the data.\n",
    "Underfitting is an example of and high bias and high variance model:\n",
    "Characteristics:\n",
    "1. Simple model with limited capacity.\n",
    "2. Sensitive to fluctuation in the dataset. \n",
    "3. Modiefies a realistic model to simplistic model\n",
    "4. Makes a lot of assumption on the patterns in  data.\n",
    "Performance:\n",
    "1. Low accuracy on training data  and low accuracy on test data.\n",
    "2. Consistently overpredict or underpredict different variables across datasets\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a95c349-00a6-4d07-9297-977c7ef55343",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q.7. Regularization is a technique used to avoid overfitting in ML by adding a penalty term to model's loss function. This penalty term discourages \n",
    "overly complex models by penalizing larger parameter values.\n",
    "Regularization helps to fit a training data well to realize a model that works better on training data.\n",
    "Inadequate regularization leads to overfitting and excessive regularisation leads to underfitting.\n",
    "There are two types of regularization:-\n",
    "1. L1 regularization - Adds a penalty term proportional to the absolute value of the model's coefficient to the loss function. \n",
    "Loss_with_L1 = Loss_without_regularization + λ * ||w||₁\n",
    "Loss_with_L1: Loss function with L1 regularization.\n",
    "Loss_without_regularization: Original loss function.\n",
    "λ (lambda): Regularization parameter that controls the strength of regularization.\n",
    "||w||₁: L1 norm of the model's weight vector.\n",
    "2. L2 regularisation - Adds a penalty term proportional to the square of the absolute value of the model's coefficient to the loss function. \n",
    "Loss_with_L2 = Loss_without_regularization + λ * ||w||₂²\n",
    "Where:\n",
    "Loss_with_L2: Loss function with L2 regularization.\n",
    "Loss_without_regularization: Original loss function.\n",
    "λ (lambda): Regularization parameter that controls the strength of regularization.\n",
    "||w||₂²: L2 norm (Euclidean norm) of the model's weight vector squared.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
